
  ==========================================
  Studio Pro version: 9.1.3
  Started at: 1/31/2023, 2:55:54 PM
  ==========================================
  

[2023-01-31T21:56:42.088Z] : [success]: Robot saved successfully

[2023-01-31T21:56:44.596Z] : [info]: ---------------------------------------------

[2023-01-31T21:56:44.596Z] : [success]: Bot started

[2023-01-31T21:56:44.597Z] : [info]: Robot start

[2023-01-31T21:58:10.694Z] : [success]: Bot finished successfully, total execution time: 1m 26s 95ms

[2023-01-31T21:58:10.695Z] : [info]: ---------------------------------------------

[2023-01-31T21:59:32.782Z] : [success]: Robot saved successfully

[2023-01-31T22:02:42.026Z] : [success]: Robot saved successfully

[2023-01-31T22:02:42.079Z] : [success]: Bot started

[2023-01-31T22:02:42.080Z] : [info]: Robot start

[2023-01-31T22:03:00.295Z] : [error]: No elements were found according to your selection. It may happen because of a wrong selector or because the element takes more time to appear on the screen. Try modifying the selector or increasing the element timeout and run the bot again.

[2023-01-31T22:03:00.297Z] : [info]: Total execution time: 18s 215ms

[2023-01-31T22:03:00.297Z] : [info]: ---------------------------------------------

[2023-01-31T22:03:25.510Z] : [success]: Robot saved successfully

[2023-01-31T22:03:25.561Z] : [success]: Bot started

[2023-01-31T22:03:25.562Z] : [info]: Robot start

[2023-01-31T22:03:52.224Z] : [info]: CNN
 — 

Two months after OpenAI unnerved some educators with the public release of ChatGPT, an AI chatbot that can help students and professionals generate shockingly convincing essays, the company is unveiling a new tool to help teachers adapt.

OpenAI on Tuesday announced a new feature, called an “AI text classifier,” that allows users to check if an essay was written by a human or AI. But even OpenAI admits it’s “imperfect.”

ChatGPT passes exams from law and business schools

The tool, which works on English AI-generated text, is powered by a machine learning system that takes an input and assigns it to several categories. In this case, after pasting a body of text such as a school essay into the new tool, it will give one of five possible outcomes, ranging from “likely generated by AI” to “very unlikely.”

Lama Ahmad, policy research director at OpenAI, told CNN that educators have been asking for a ChatGPT feature like this, but warns it should be “taken with a grain of salt.”

“We really don’t recommend taking this tool in isolation because we know that it can be wrong and will be wrong at times – much like using AI for any kind of assessment purposes,” Ahmad said. “We are emphasizing how important it is to keep a human in the loop … and that it’s just one data point among many others.”

Ahmad notes that some teachers have referenced past examples of student work and writing style to gauge whether it was written by the student. While the new tool might provide another reference point, Ahmad said “teachers need to be really careful in how they include it in academic dishonesty decisions.”

Since it was made available in late November, ChatGPT has been used to generate original essays, stories and song lyrics in response to user prompts. It has drafted research paper abstracts that fooled some scientists. It even recently passed law exams in four courses at the University of Minnesota, another exam at University of Pennsylvania’s Wharton School of Business and a US medical licensing exam.

In the process, it has raised alarms among some educators. Public schools in New York City and Seattle have already banned students and teachers from using ChatGPT on the district’s networks and devices. Some educators are now moving with remarkable speed to rethink their assignments in response to ChatGPT, even as it remains unclear how widespread use is of the tool among students and how harmful it could really be to learning.

OpenAI now joins a small but growing list of efforts to help educators detect when a written work is generated by ChatGPT. Some companies such as Turnitin are actively working on ChatGPT plagiarism detection tools that could help teachers identify when assignments are written by the tool. Meanwhile, Princeton student Edward Tuan told CNN more than 95,000 people have already tried the beta version of his own ChatGPT detection feature, called ZeroGPT, noting there has been “incredible demand among teachers” so far.

Jan Leike – a lead on the OpenAI alignment team, which works to make sure the AI tool is aligned with human values – listed several reasons for why detecting plagiarism via ChatGPT may be a challenge. People can edit text to avoid being identified by the tool, for example. It will also “be best at identifying text that is very similar to the kind of text that we’ve trained it on.”

In addition, the company said it’s impossible to determine if predictable text – such as a list of the first 1,000 prime numbers – was written by AI or a human because the correct answer is always the same, according to a company blog post. The classifier is also “very unreliable” on short texts below 1,000 characters.

Teachers are adapting to concerns about a powerful new AI tool

During a demo with CNN ahead of Tuesday’s launch, ChatGPT successfully labeled several bodies of work. An excerpt from the book “Peter Pan,” for example, was deemed “unlikely” to be AI generated. In the company blog post, however, OpenAI said it incorrectly labeled human-written text as AI-written 5% of the time.

Despite the possibility of false positives, Leike said the company aims to use the tool to spark conversations around AI literacy and possibly deter people from claiming that AI-written text was created by a human. He said the decision to release the new feature also stems from the debate around whether humans have a right to know if they’re interacting with AI.

“This question is much bigger than what we are doing here; society as a whole has to grapple with that question,” he said.

OpenAI said it encourages the general public to share their feedback on the AI check feature. Ahmad said the company continues to talk with K-12 educators and those at the collegiate level and beyond, such as Harvard University and the Stanford Design School.

The company sees its role as “an educator to the educators,” according to Ahmad, in the sense that OpenAI wants to make them more “aware about the technologies and what they can be used for and what they should not be used for.”

“We’re not educators ourselves – we’re very aware of that – and so our goals are really to help equip teachers to deploy these models effectively in and out of the classroom,” Ahmad said. “That means giving them the language to speak about it, help them understand the capabilities and the limitations, and then secondarily through them, equip students to navigate the complexities that AI is already introducing in the world.”

[2023-01-31T22:04:10.024Z] : [error]: No elements were found according to your selection. It may happen because of a wrong selector or because the element takes more time to appear on the screen. Try modifying the selector or increasing the element timeout and run the bot again.

[2023-01-31T22:04:10.026Z] : [info]: Total execution time: 44s 462ms

[2023-01-31T22:04:10.026Z] : [info]: ---------------------------------------------

[2023-01-31T22:05:27.949Z] : [success]: Robot saved successfully

[2023-01-31T22:05:27.993Z] : [success]: Bot started

[2023-01-31T22:05:27.994Z] : [info]: Robot start

[2023-01-31T22:05:49.536Z] : [info]: CNN
 — 

Two months after OpenAI unnerved some educators with the public release of ChatGPT, an AI chatbot that can help students and professionals generate shockingly convincing essays, the company is unveiling a new tool to help teachers adapt.

OpenAI on Tuesday announced a new feature, called an “AI text classifier,” that allows users to check if an essay was written by a human or AI. But even OpenAI admits it’s “imperfect.”

ChatGPT passes exams from law and business schools

The tool, which works on English AI-generated text, is powered by a machine learning system that takes an input and assigns it to several categories. In this case, after pasting a body of text such as a school essay into the new tool, it will give one of five possible outcomes, ranging from “likely generated by AI” to “very unlikely.”

Lama Ahmad, policy research director at OpenAI, told CNN that educators have been asking for a ChatGPT feature like this, but warns it should be “taken with a grain of salt.”

“We really don’t recommend taking this tool in isolation because we know that it can be wrong and will be wrong at times – much like using AI for any kind of assessment purposes,” Ahmad said. “We are emphasizing how important it is to keep a human in the loop … and that it’s just one data point among many others.”

Ahmad notes that some teachers have referenced past examples of student work and writing style to gauge whether it was written by the student. While the new tool might provide another reference point, Ahmad said “teachers need to be really careful in how they include it in academic dishonesty decisions.”

Since it was made available in late November, ChatGPT has been used to generate original essays, stories and song lyrics in response to user prompts. It has drafted research paper abstracts that fooled some scientists. It even recently passed law exams in four courses at the University of Minnesota, another exam at University of Pennsylvania’s Wharton School of Business and a US medical licensing exam.

In the process, it has raised alarms among some educators. Public schools in New York City and Seattle have already banned students and teachers from using ChatGPT on the district’s networks and devices. Some educators are now moving with remarkable speed to rethink their assignments in response to ChatGPT, even as it remains unclear how widespread use is of the tool among students and how harmful it could really be to learning.

OpenAI now joins a small but growing list of efforts to help educators detect when a written work is generated by ChatGPT. Some companies such as Turnitin are actively working on ChatGPT plagiarism detection tools that could help teachers identify when assignments are written by the tool. Meanwhile, Princeton student Edward Tuan told CNN more than 95,000 people have already tried the beta version of his own ChatGPT detection feature, called ZeroGPT, noting there has been “incredible demand among teachers” so far.

Jan Leike – a lead on the OpenAI alignment team, which works to make sure the AI tool is aligned with human values – listed several reasons for why detecting plagiarism via ChatGPT may be a challenge. People can edit text to avoid being identified by the tool, for example. It will also “be best at identifying text that is very similar to the kind of text that we’ve trained it on.”

In addition, the company said it’s impossible to determine if predictable text – such as a list of the first 1,000 prime numbers – was written by AI or a human because the correct answer is always the same, according to a company blog post. The classifier is also “very unreliable” on short texts below 1,000 characters.

Teachers are adapting to concerns about a powerful new AI tool

During a demo with CNN ahead of Tuesday’s launch, ChatGPT successfully labeled several bodies of work. An excerpt from the book “Peter Pan,” for example, was deemed “unlikely” to be AI generated. In the company blog post, however, OpenAI said it incorrectly labeled human-written text as AI-written 5% of the time.

Despite the possibility of false positives, Leike said the company aims to use the tool to spark conversations around AI literacy and possibly deter people from claiming that AI-written text was created by a human. He said the decision to release the new feature also stems from the debate around whether humans have a right to know if they’re interacting with AI.

“This question is much bigger than what we are doing here; society as a whole has to grapple with that question,” he said.

OpenAI said it encourages the general public to share their feedback on the AI check feature. Ahmad said the company continues to talk with K-12 educators and those at the collegiate level and beyond, such as Harvard University and the Stanford Design School.

The company sees its role as “an educator to the educators,” according to Ahmad, in the sense that OpenAI wants to make them more “aware about the technologies and what they can be used for and what they should not be used for.”

“We’re not educators ourselves – we’re very aware of that – and so our goals are really to help equip teachers to deploy these models effectively in and out of the classroom,” Ahmad said. “That means giving them the language to speak about it, help them understand the capabilities and the limitations, and then secondarily through them, equip students to navigate the complexities that AI is already introducing in the world.”

[2023-01-31T22:06:13.229Z] : [info]: CNN
 — 

Mercedes-Benz will take a step towards offering a self driving car in the United States, or at least in some states, when it begins selling cars featuring its new Drive Pilot system later this year.

Mercedes’ Drive Pilot system is designed to work on highways in dense traffic at speeds of less than 40 miles per hour. Unlike traffic jam assist features already available throughout the US on a number of luxury models today, including Mercedes-Benz cars, the Drive Pilot system allows the driver to entirely disengage from the act of driving. When the system is in operation, Mercedes considers it safe for the driver not to pay attention to the road – although the driver still has to be ready to take back control if needed, such as if the traffic situation changes or if the system encounters an unusual situation it’s not capable of handling.

The Mercedes system is considered Level 3 Automation, as defined by the Society of Automotive Engineers. It’s more automated than a Level 2 system, like Tesla’s Autopilot, General Motors’ Super Cruise and Ford’s BlueCruise, in which the vehicle’s brakes and steering operate on their own in certain situations but the driver is still required to pay attention to the road at all times.

In a Level 3 system, “You are not driving when these automated driving features are engaged - even if you are seated ‘in the driver’s seat,’” according to the SAE

The driver could, for instance, check emails on their phone or watch a video. Even Tesla’s Autopilot and so-called “Full Self-Driving” technologies require that the driver pay attention to the road outside the car at all times.

“In the modern world, time is one of the most precious commodities, and giving back time to our customers is a core element in our strategy to build the world’s most desirable cars,” said Markus Schäfer, chief technology officer for Mercedes-Benz.

The system complies with Nevada’s traffic regulations for autonomous vehicles, according to Mercedes, which says it hopes to get certification in California soon. The system will be available on model year 2024 Mercedes EQS and S-class models, which go on sale in the US later this year. The system will only work on certain mapped highways in states where it has been deemed legal such as Nevada and, possibly soon, California.

Among other technologies, the Mercedes system relies on lidar, which is similar to radar but uses laser light, rather than radio waves, to detect objects in its surroundings. Lidar can provide much more detail about a vehicles’ surroundings than radar or cameras alone and many experts feel it is a necessity for safe autonomous vehicles. Elon Musk, the CEO of Tesla, however, has said cameras alone are sufficient.

The Mercedes system also uses a rear-facing a camera in the back window, a microphone to listen for emergency vehicles and road wetness sensors inside the wheel well. It also relies on high-definition three-dimensional mapping data that’s regularly updated as well as an ultra-precise vehicle positioning system that’s much more accurate than ordinary GPS, according to Mercedes-Benz.

[2023-01-31T22:06:23.662Z] : [error]: No elements were found according to your selection. It may happen because of a wrong selector or because the element takes more time to appear on the screen. Try modifying the selector or increasing the element timeout and run the bot again.

[2023-01-31T22:06:23.665Z] : [info]: Total execution time: 55s 667ms

[2023-01-31T22:06:23.665Z] : [info]: ---------------------------------------------

